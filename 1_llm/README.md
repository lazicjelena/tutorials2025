# [[M2L2025](https://www.m2lschool.org/home)] Tutorial 1: Large Language Models

**Authors:** [Aleksandar Stanic](https://astanic.github.io/), [Mandana Samiei](https://mandanasmi.github.io/)

--- 
This is the tutorial of the 2025 [Mediteranean Machine Learning Summer School](https://www.m2lschool.org) on Large Language Models!

This tutorial will explore the fundamental aspects of Large Language Models (LLMs). Basic Python programming skils are expected. Prior knowledge of standard NLP techniques (e.g. text tokenization and classification with ML) is beneficial but optional when working through the notebooks as they assume minimal prior knowledge.

This tutorial combines detailed analysis and development of essential LLM concepts via custom (i.e. from scratch) implementations. Other necessary LLM components will be developed using PyTorch. As a result, the tutorial offers deep understanding of LLMs and facilitates easy usage in future applications.

## Outline

* Part I: Transformer Architecture
* Part II: Mixture of Experts and Optimizations (KV cache, Attention Variants and Speculative Decoding)
* Part III: Parameter Efficient Fine-tuning, LoRA and RAG


### Notebooks

#### Part I: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](part1_EXERCISES.ipynb)


#### Part II: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](part2_EXERCISES.ipynb)


#### Part III: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](part3_EXERCISES.ipynb)
